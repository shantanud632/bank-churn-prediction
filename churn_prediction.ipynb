{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0c3a3c-eb89-4930-8739-b7b39dc69901",
   "metadata": {},
   "source": [
    "üìù Title + Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235effb-fb96-4e74-839d-ccf45b5c0c50",
   "metadata": {},
   "source": [
    "# üß† Bank Customer Churn Prediction\n",
    "\n",
    "This project predicts whether a bank customer will churn using machine learning models like Logistic Regression, Random Forest, and XGBoost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeca275-410c-47d1-90ba-7e6a629b38da",
   "metadata": {},
   "source": [
    "üì• Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7befed4f-19ca-425c-9920-3f6d855e24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"churn_modeling.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7751ab9-5af6-4faf-84d5-6d0058d184d1",
   "metadata": {},
   "source": [
    "üßπ Data Cleaning + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2781cd1-6217-4097-ac27-464ce53a31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop(columns=['CustomerId', 'Surname'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "df_cleaned['Gender'] = LabelEncoder().fit_transform(df_cleaned['Gender'])\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=['Geography'], drop_first=True)\n",
    "\n",
    "X = df_cleaned.drop(columns=['Churn'])\n",
    "y = df_cleaned['Churn']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c15121-d977-4262-b7f8-5a8eff828b80",
   "metadata": {},
   "source": [
    "ü§ñ Model Training + Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff1327-128c-45b0-a7b5-c7dbe138e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=50, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Training: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"‚úÖ Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"üìä Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"üìâ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e9213-5673-4b9d-84de-33389b29c55b",
   "metadata": {},
   "source": [
    "üìà ROC Curve Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502274b-dc85-41d1-a527-e1ff02018958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, model in models.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('üìà ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab972e-5093-4bf7-baa9-96a87ca8f636",
   "metadata": {},
   "source": [
    "Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30496d-dd39-4c31-aed6-ec27cec5b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = models[\"XGBoost\"]\n",
    "importances = xgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(feature_names, importances)\n",
    "plt.title(\"üîç XGBoost Feature Importance\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1967b5a-4896-4894-b436-75bf0b848e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ‚úÖ Conclusion\n",
    "\n",
    "- Logistic Regression was weakest at detecting churn\n",
    "- XGBoost had the best balance of accuracy and recall\n",
    "- Feature Importance revealed Age, Activity, Geography mattered most\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
